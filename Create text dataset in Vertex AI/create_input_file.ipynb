{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0da0fd-8c5b-4aa7-90ef-8f115aef1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from google.cloud import storage\n",
    "\n",
    "# Define Cloud Storage client and bucket to which files will be exported\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('c4ds-europe-west4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc8793-bd15-4526-aede-6d55aa6ce515",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create text classification input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9258b-f103-4bbb-a295-dc46bfc23c98",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/datasets/saurabhshahane/ecommerce-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d6b2a-1b89-4009-a924-a54432d12c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('data/ecommerceDataset.csv', names=['label','text'], header=None)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3306b2-b643-4f96-ae4e-b630ac7a90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full DataFrame into 2 lists: \n",
    "# 1st list contains labels\n",
    "label_list = list(df.iloc[:,0])\n",
    "\n",
    "# 2nd list contains text\n",
    "text_list = list(df.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66462540-d480-49e8-b5c6-53a3494cfb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2 above defined arrays to create a JSONL input file according to the requirements\n",
    "input_json = [{\"classificationAnnotation\": {\"displayName\": label}, \"textContent\": text} for label, text in zip(label_list, text_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd239e1-14f4-49c0-8567-fd2df10b5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save input file locally\n",
    "with open('input_file_text_classification.jsonl', 'w') as file:\n",
    "    for entry in input_json:\n",
    "        json.dump(entry, file)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4668b-a5ef-4482-94dd-8c5e116c0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export input file to Cloud Storage\n",
    "blob = bucket.blob('text/input_file_text_classification.jsonl')\n",
    "blob.upload_from_filename('input_file_text_classification.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4d346-96a9-45ed-b84c-60bbaabf5f69",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create sentiment analysis input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512129d-43ce-4788-8ef1-f62dc07ef414",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ddf3b-5903-41ef-ad63-d847183b1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('data/Reddit_Data.csv')\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43389233-2b47-47eb-a389-b189d9067353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map values in category column from [-1,0,1] to [0,1,2] - A sentiment value must be an integer from 0 to 10\n",
    "df['category'] = df['category'].map({-1: 0, 0: 1, 1: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d3358-a487-4e4b-88ee-667d9170e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full DataFrame into 2 lists: \n",
    "# 1st list contains labels\n",
    "text_list = list(df.iloc[:,0])\n",
    "\n",
    "# 2nd list contains text\n",
    "sentiment_list = list(df.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71554334-cbf1-47db-b6b3-e50343575c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2 above defined arrays to create a JSONL input file according to requirements\n",
    "input_json = [{\"sentimentAnnotation\": {\"sentiment\": sentiment, \"sentimentMax\": 2}, \"textContent\": text} for sentiment, text in zip(sentiment_list, text_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64c2e7-5cf4-49c4-9196-0f1fb6e2b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save input file locally\n",
    "with open('input_file_sentiment_analysis.jsonl', 'w') as file:\n",
    "    for entry in input_json:\n",
    "        json.dump(entry, file)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29808d32-f4b2-499c-9003-34e572972263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export input file to Cloud Storage\n",
    "blob = bucket.blob('text/input_file_sentiment_analysis.jsonl')\n",
    "blob.upload_from_filename('input_file_sentiment_analysis.jsonl')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
